#!/usr/bin/env python
"""Run uvspec for a given experimental setup defined in a libradtran_write_input_file_experiment.py file

Given the experiment name, campaign, the flight and the path to the uvspec executable, this script calls ``uvspec`` for each input file and writes a log and output file.
It does so in parallel, checking how many CPUs are available.
After that the output files are merged into one data frame and information from the input file is added to write one netCDF file.

The script can be run for one flight or for all flights.

**Required User Input:**

* experiment, name of the experiment defining the input path with all input files generated by the corresponding :py:mod:`libradtran_write_input_file_experiment.py` script and the netCDF file name
* campaign
* flight_key (e.g. "RF17")
* path to uvspec executable

**Output:**

* out and log file for each simulation
* log file for each flight
* netCDF file with simulation in- and output

*author*: Johannes RÃ¶ttenbacher
"""
if __name__ == "__main__":
    # %% module import
    import pylim.helpers as h
    import pylim.halo_ac3 as meta
    from pylim.libradtran import get_info_from_libradtran_input
    import numpy as np
    import pandas as pd
    import xarray as xr
    import os
    from operator import itemgetter
    from subprocess import Popen
    from tqdm import tqdm
    from joblib import cpu_count
    import datetime as dt
    from pysolar.solar import get_azimuth

    # %% set options
    experiment = "icecloud2"  # string defining experiment name, will be used for input path and netCDF filename
    campaign = "halo-ac3"
    # get all flights from dictionary
    all_flights = [key for key in meta.transfer_calibs.keys()] if campaign == "cirrus-hl" else list(
        meta.flight_names.values())
    all_flights = all_flights[18:19]  # select specific flight[s] if needed

    uvspec_exe = "/opt/libradtran/2.0.4/bin/uvspec"
    solar_flag = True
    # set base paths
    libradtran_base_path = h.get_path("libradtran_exp", campaign=campaign)

    # %% run for all flights
    for flight in all_flights:
        flight_key = flight[-4:] if campaign == "halo-ac3" else flight
        libradtran_path = os.path.join(libradtran_base_path, "wkdir", flight_key, f"{experiment}")
        date = flight[9:17] if campaign == "halo-ac3" else flight[7:15]
        # check if outfile exists already and give a warning
        nc_filepath = f"{libradtran_base_path}/{campaign.swapcase()}_HALO_libRadtran_simulation_{experiment}_{date}_{flight_key}.nc"
        if os.path.isfile(nc_filepath):
            answer = input(f"{nc_filepath}\nalready exists!\n Do you want to overwrite it? (y/n)")
            if answer == "y":
                pass
            else:
                continue
        # get files
        input_files = [os.path.join(libradtran_path, f) for f in os.listdir(libradtran_path) if
                       f.endswith(".inp") and f.startswith(date)]
        input_files.sort()  # sort input files -> output files will be sorted as well
        output_files = [f.replace(".inp", ".out") for f in input_files]
        error_logs = [f.replace(".out", ".log") for f in output_files]

        # %% setup logging
        try:
            file = __file__
        except NameError:
            file = None
        log = h.setup_logging("./logs", file, flight_key)
        log.info(f"Options Given:\ncampaign: {campaign}\nflight: {flight}\nsolar_flag: {solar_flag}\n"
                 f"uvspec_exe: {uvspec_exe}\nScript started: {dt.datetime.utcnow():%c UTC}\n"
                 f"wkdir: {libradtran_path}")

        # %% call uvspec for all files
        processes = set()
        max_processes = cpu_count() - 4
        tqdm_desc = f"libRadtran simulations {flight}"
        for infile, outfile, log_file in zip(tqdm(input_files, desc=tqdm_desc), output_files, error_logs):
            with open(infile, "r") as ifile, open(outfile, "w") as ofile, open(log_file, "w") as lfile:
                processes.add(Popen([uvspec_exe], stdin=ifile, stdout=ofile, stderr=lfile))
            if len(processes) >= max_processes:
                os.wait()
                processes.difference_update([p for p in processes if p.poll() is not None])

        # wait for all simulations to finish
        while len(processes) > 0:
            os.wait()
            # this will remove elements of the set which are also in the list.
            # the list has only terminated processes in it,
            # p.poll returns a non None value if the process is still running
            processes.difference_update([p for p in processes if p.poll() is not None])

        # %% check if all simulations created an output and rerun them if not
        file_check = sum([os.path.getsize(file) == 0 for file in output_files])
        # if file size is 0 -> file is empty
        counter = 0  # add a counter to terminate loop if necessary
        try:
            while file_check > 0:
                files_to_rerun = [f for f in input_files if os.path.getsize(f.replace(".inp", ".out")) == 0]
                # rerun simulations
                for infile in tqdm(files_to_rerun, desc="redo libRadtran simulations"):
                    with open(infile, "r") as ifile, \
                            open(infile.replace(".inp", ".out"), "w") as ofile, \
                            open(infile.replace(".inp", ".log"), "w") as lfile:
                        processes.add(Popen([uvspec_exe], stdin=ifile, stdout=ofile, stderr=lfile))
                    if len(processes) >= max_processes:
                        os.wait()
                        processes.difference_update([p for p in processes if p.poll() is not None])

                # wait for all simulations to finish
                while len(processes) > 0:
                    # this will remove elements of the set which are also in the list.
                    # the list has only terminated processes in it,
                    # p.poll returns a non None value if the process is still running
                    processes.difference_update([p for p in processes if p.poll() is not None])
                # update file_check
                file_check = sum([os.path.getsize(file) == 0 for file in output_files])
                counter += 1
                if counter > 10:
                    raise UserWarning(f"Simulation of {files_to_rerun} does not compute!\nCheck for other errors!")
        except UserWarning as e:
            log.info(f"{e}\nMoving to next flight")
            continue

        # %% merge output files and write a netCDF file
        latitudes, longitudes, time_stamps, saa, exp_settings = list(), list(), list(), list(), list()

        log.info("Reading input files and extracting information from it...")
        for infile in tqdm(input_files, desc="Input files"):
            input_info = get_info_from_libradtran_input(infile)
            lat, lon, ts, header, wavelengths, integrate_flag, zout = itemgetter("latitude", "longitude", "time_stamp",
                                                                           "header", "wavelengths",
                                                                           "integrate_flag", "zout")(input_info)
            latitudes.append(lat)
            longitudes.append(lon)
            time_stamps.append(ts)
            # convert timestamp to datetime object with timezone information
            dt_ts = ts.to_pydatetime().astimezone(dt.timezone.utc)
            saa.append(get_azimuth(lat, lon, dt_ts))  # calculate solar azimuth angle
            exp_settings.append(input_info["experiment_settings"])

        log.info("Merging all output files and adding information from input files...")
        output = pd.concat([pd.read_csv(file, header=None, names=header, sep="\s+").assign(time=ts)
                            for file, ts in zip(tqdm(output_files, desc="Output files"), time_stamps)])
        # convert output altitude to m
        output["zout"] = output["zout"] * 1000
        len_zout = len(input_info["zout"])

        if "lambda" in header and len_zout > 1 and exp_settings[0] is not None:
            # here a spectral simulation with outputs on multiple levels and different experimental setups has been
            # performed
            nr_wavelengths = len(output["lambda"].unique())  # retrieve the number of wavelengths which were simulated
            len_experiment = nr_wavelengths * len_zout
            experiment_settings = {k: list() for k in exp_settings[0].keys()}
            for d in exp_settings:
                for key, value in d.items():
                    experiment_settings[key].append(np.repeat(value, len_experiment))

            # add numeric experiment settings to dataframe and extract additional dimensions for adding to index
            additional_dimensions = list()
            for key in experiment_settings:
                try:
                    output[key] = pd.to_numeric(np.array(experiment_settings[key]).flatten())
                    additional_dimensions.append(key)
                except ValueError as e:
                    log.debug(f"{e}\n"
                              f"Variable '{key}' with value: '{np.unique(experiment_settings[key])}' not added to"
                              f" dataframe.")

        elif "lambda" in header and len_zout > 1:
            # here a spectral simulation with outputs on multiple levels has been performed
            nr_wavelengths = len(output["lambda"].unique())  # retrieve the number of wavelengths which were simulated

        elif "lambda" in header and len_zout == 1:
            # here a spectral simulation for one altitude has been performed resulting in more than one line per file
            nr_wavelengths = len(output["lambda"].unique())  # retrieve the number of wavelengths which were simulated
            # retrieve wavelength independent variables from files
            # since the data frames are all concatenated with their original index we can use only the rows with index 0
            zout = output.loc[0, "zout"]
            sza = output.loc[0, "sza"]

        if len_zout == 1:
            output = output.set_index(["time"]) if integrate_flag else output.set_index(["time", "lambda"])
        elif exp_settings[0] is None:
            output = output.set_index(["time", "zout"]) if integrate_flag else output.set_index(
                ["time", "lambda", "zout"])
        else:
            if integrate_flag:
                output = output.set_index(["time", "zout", additional_dimensions[0], additional_dimensions[1]])
            else:
                output = output.set_index(["time", "lambda", "zout", additional_dimensions[0], additional_dimensions[1]])

        # calculate direct fraction
        output["direct_fraction"] = output["edir"] / (output["edir"] + output["edn"])
        if solar_flag:
            # convert mW/m2 to W/m2 (see page 43 of manual)
            output["edir"] = output["edir"] / 1000
            output["eup"] = output["eup"] / 1000
            output["edn"] = output["edn"] / 1000
            # calculate solar clear sky downward irradiance
            if "eglo" in output:
                output["eglo"] = output["eglo"] / 1000
            else:
                output["eglo"] = output["edir"] + output["edn"]

        # set up some metadata
        integrate_str = "integrated " if integrate_flag else ""
        wavelength_str = f"wavelength range {wavelengths[0]} - {wavelengths[1]} nm"

        # set up metadata dictionaries for solar (shortwave) flux
        var_attrs_solar = dict(
            albedo=dict(units="1", long_name="surface albedo", standard_name="surface_albedo"),
            altitude=dict(units="m", long_name="height above mean sea level", standard_name="altitude"),
            direct_fraction=dict(units="1", long_name="direct fraction of downward irradiance", comment=wavelength_str),
            edir=dict(units="W m-2", long_name=f"{integrate_str}direct beam irradiance",
                      standard_name="direct_downwelling_shortwave_flux_in_air",
                      comment=wavelength_str),
            edn=dict(units="W m-2", long_name=f"{integrate_str}diffuse downward irradiance",
                     standard_name="diffuse_downwelling_shortwave_flux_in_air_assuming_clear_sky",
                     comment=wavelength_str),
            eup=dict(units="W m-2", long_name=f"{integrate_str}diffuse upward irradiance",
                     standard_name="surface_upwelling_shortwave_flux_in_air_assuming_clear_sky",
                     comment=wavelength_str),
            eglo=dict(units="W m-2", long_name=f"{integrate_str}global solar downward irradiance",
                      standard_name="solar_irradiance", comment=wavelength_str),
            enet=dict(units="W m-2", long_name=f"{integrate_str}net irradiance", comment=wavelength_str),
            heat=dict(units="K day-1", long_name="heating rate"),
            latitude=dict(units="degrees_north", long_name="latitude", standard_name="latitude"),
            longitude=dict(units="degrees_east", long_name="longitude", standard_name="longitude"),
            saa=dict(units="degree", long_name="solar azimuth angle", standard_name="solar_azimuth_angle",
                     comment="clockwise from north"),
            sza=dict(units="degree", long_name="solar zenith angle", standard_name="solar_zenith_angle",
                     comment="0 deg = zenith"),
            CLWD=dict(units="g m^-3", long_name="cloud liquid water density",
                      standard_name="mass_concentration_of_cloud_liquid_water_in_air"),
            CIWD=dict(units="g m^-3", long_name="cloud ice water density",
                      standard_name="mass_concentration_of_cloud_ice_water_in_air"),
            p=dict(units="hPa", long_name="atmospheric pressure", standard_name="air_pressure"),
            T=dict(units="K", long_name="air temperature", standard_name="air_temperature"),
            wavelength=dict(units="nm", long_name="wavelength", standard_name="radiation_wavelength"),
            re_ice=dict(units="mum", long_name="input ice effective radius"),
            iwc=dict(units="g m^-3", long_name="input ice water content")
        )

        # set up metadata dictionaries for terrestrial (longwave) flux
        var_attrs_terrestrial = dict(
            albedo=dict(units="1", long_name="surface albedo", standard_name="surface_albedo"),
            altitude=dict(units="m", long_name="height above mean sea level", standard_name="altitude"),
            direct_fraction=dict(units="1", long_name="direct fraction of downward irradiance", comment=wavelength_str),
            edir=dict(units="W m-2", long_name=f"{integrate_str}direct beam irradiance",
                      standard_name="direct_downwelling_longwave_flux_in_air",
                      comment=wavelength_str),
            edn=dict(units="W m-2", long_name=f"{integrate_str}downward irradiance",
                     standard_name="downwelling_longwave_flux_in_air_assuming_clear_sky",
                     comment=wavelength_str),
            eup=dict(units="W m-2", long_name=f"{integrate_str}upward irradiance",
                     standard_name="surface_upwelling_longwave_flux_in_air_assuming_clear_sky",
                     comment=wavelength_str),
            latitude=dict(units="degrees_north", long_name="latitude", standard_name="latitude"),
            longitude=dict(units="degrees_east", long_name="longitude", standard_name="longitude"),
            saa=dict(units="degree", long_name="solar azimuth angle", standard_name="soalr_azimuth_angle",
                     comment="clockwise from north"),
            sza=dict(units="degree", long_name="solar zenith angle", standard_name="solar_zenith_angle",
                     comment="0 deg = zenith"),
            CLWD=dict(units="g m^-3", long_name="cloud liquid water density",
                      standard_name="mass_concentration_of_cloud_liquid_water_in_air"),
            CIWD=dict(units="g m^-3", long_name="cloud ice water density",
                      standard_name="mass_concentration_of_cloud_ice_water_in_air"),
            p=dict(units="hPa", long_name="atmospheric pressure", standard_name="air_pressure"),
            T=dict(units="K", long_name="air temperature", standard_name="air_temperature"),
            wavelength=dict(units="nm", long_name="wavelength", standard_name="radiation_wavelength"),
            re_ice=dict(units="mum", long_name="input ice effective radius"),
            iwc=dict(units="g m^-3", long_name="input ice water content")
        )

        # set up global attributes
        # CIRRUS-HL
        attributes = dict(
            title=f"Simulated downward and upward irradiance along flight track for experiment {experiment}",
            Conventions="CF-1.9",
            camapign_id=f"{campaign.swapcase()}",
            platform_id="HALO",
            version_id="1",
            comment=f"CIRRUS-HL Campaign, Oberpfaffenhofen, Germany, {flight}",
            contact="PI: m.wendisch@uni-leipzig.de, Data: johannes.roettenbacher@uni-leipzig.de",
            history=f"Created {dt.datetime.utcnow():%c} UTC",
            institution="Leipzig Institute for Meteorology, Leipzig University, Stephanstr.3, 04103 Leipzig, Germany",
            source="libRadtran 2.0.4",
            references="Emde et al. 2016, 10.5194/gmd-9-1647-2016"
        )
        # HALO-AC3
        global_attrs = dict(
            title=f"Simulated downward and upward irradiance along flight track for experiment {experiment}",
            Conventions="CF-1.9",
            campaign_id=f"{campaign.swapcase()}",
            platform_id="HALO",
            version_id="1",
            institution="Leipzig Institute for Meteorology, Leipzig, Germany, Stephanstr.3, 04103 Leipzig, Germany",
            history=f"created {dt.datetime.utcnow():%c} UTC",
            contact="Johannes RÃ¶ttenbacher, johannes.roettenbacher@uni-leipzig.de",
            PI="AndrÃ© Ehrlich, a.ehrlich@uni-leipzig.de",
            source="libRadtran 2.0.4",
            references="Emde et al. 2016, 10.5194/gmd-9-1647-2016",
        )

        encoding = dict(time=dict(units="seconds since 2017-01-01"))

        ds = output.to_xarray()

        wavelength_independent_variables = ["p", "T", "CLWD", "CIWD"]
        # drop wavelength dimension from wavelength independent variables by either overwriting them or dropping the dim
        if not integrate_flag and len_zout == 1:
            ds = ds.assign(zout=xr.DataArray(zout, coords={"time": ds.time}))
            ds = ds.assign(sza=xr.DataArray(sza, coords={"time": ds.time}))
        elif not integrate_flag and len_zout > 1:
            dims = ds.sza.dims
            sza = ds.sza
            for i, dim in enumerate(dims):
                if dim != "time":
                    sza = sza.isel({f"{dim}": 0}, drop=True)
            ds["sza"] = sza
            for var in wavelength_independent_variables:
                if var in ds:
                    ds[var] = ds[var].isel({"lambda": 0}, drop=True)

        # add the time dependent variables from the input files
        ds = ds.assign(saa=xr.DataArray(np.unique(saa), coords={"time": ds.time}))
        ds = ds.assign(latitude=xr.DataArray(np.unique(latitudes), coords={"time": ds.time}))
        ds = ds.assign(longitude=xr.DataArray(np.unique(longitudes), coords={"time": ds.time}))


        ds.attrs = global_attrs if campaign == "halo-ac3" else attributes  # assign global attributes
        ds = ds.rename({"zout": "altitude"})
        if "lambda" in header:
            ds = ds.rename({"lambda": "wavelength"})
        # set attributes of each variable
        var_attrs = var_attrs_solar if solar_flag else var_attrs_terrestrial
        for var in ds:
            ds[var].attrs = var_attrs[var]
            encoding[var] = dict(_FillValue=None)  # remove the default _FillValue attribute from each variable
        for var in ds.coords:
            if var != "time":
                ds[var].attrs = var_attrs[var]
                encoding[var] = dict(_FillValue=None)  # remove the default _FillValue attribute from each variable

        # save file
        ds.to_netcdf(nc_filepath, encoding=encoding)
        log.info(f"Saved {nc_filepath}")
