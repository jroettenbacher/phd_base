#!/usr/bin/env python
"""Run uvspec for a given experimental setup defined in a libradtran_write_input_file_experiment.py file

Given the experiment name, campaign, the flight and the path to the uvspec executable, this script calls ``uvspec`` for each input file and writes a log and output file.
It does so in parallel, checking how many CPUs are available.
After that the output files are merged into one data frame and information from the input file is added to write one netCDF file.

The script can be run for one flight or for all flights.

**Required User Input:**

* experiment, name of the experiment defining the input path with all input files generated by the corresponding :py:mod:`libradtran_write_input_file_experiment.py` script and the netCDF file name
* campaign
* flight_key (e.g. "RF17")
* path to uvspec executable

**Output:**

* out and log file for each simulation
* log file for each flight
* netCDF file with simulation in- and output

*author*: Johannes RÃ¶ttenbacher
"""
if __name__ == "__main__":
    # %% module import
    import pylim.helpers as h
    import pylim.halo_ac3 as meta
    from pylim.libradtran import get_info_from_libradtran_input
    import numpy as np
    import pandas as pd
    import xarray as xr
    import os
    from subprocess import Popen
    from tqdm import tqdm
    from joblib import cpu_count
    import datetime as dt
    from pysolar.solar import get_azimuth
    import logging

    # %% set options
    experiment = "seaice_2"  # string defining experiment name, will be used for input path and netCDF filename
    campaign = "halo-ac3"
    # get all flights from dictionary
    all_flights = [key for key in meta.transfer_calibs.keys()] if campaign == "cirrus-hl" else list(meta.flight_names.values())
    all_flights = all_flights[18:19]  # select specific flight[s] if needed

    uvspec_exe = "/opt/libradtran/2.0.4/bin/uvspec"
    solar_flag = True
    solar_str = "solar" if solar_flag else "thermal"
    # set base paths
    libradtran_base_path = h.get_path("libradtran_exp", campaign=campaign)
    libradtran_path = os.path.join(libradtran_base_path, "wkdir", f"{experiment}_{solar_str}")

    # %% run for all flights
    for flight in all_flights:
        flight_key = flight[-4:] if campaign == "halo-ac3" else flight
        date = flight[9:17] if campaign == "halo-ac3" else flight[7:15]
        # check if outfile exists already and give a warning
        nc_filepath = f"{libradtran_base_path}/{campaign.swapcase()}_HALO_libRadtran_simulation_{experiment}_{solar_str}_{date}_{flight_key}.nc"
        if os.path.isfile(nc_filepath):
            answer = input(f"{nc_filepath}\nalready exists!\n Do you want to overwrite it? (y/n)")
            if answer == "y":
                pass
            else:
                continue
        # get files
        input_files = [os.path.join(libradtran_path, f) for f in os.listdir(libradtran_path) if f.endswith(".inp") and f.startswith(date)]
        input_files.sort()  # sort input files -> output files will be sorted as well
        output_files = [f.replace(".inp", ".out") for f in input_files]
        error_logs = [f.replace(".out", ".log") for f in output_files]

        # %% setup logging
        try:
            file = __file__
        except NameError:
            file = None
        log = h.setup_logging("./logs", file, flight_key)
        log.info(f"Options Given:\ncampaign: {campaign}\nflight: {flight}\nwavelength: {solar_str}\n"
                 f"uvspec_exe: {uvspec_exe}\nScript started: {dt.datetime.utcnow():%c UTC}\n"
                 f"wkdir: {libradtran_path}")
        # %% call uvspec for all files
        processes = set()
        max_processes = cpu_count() - 4
        tqdm_desc = f"libRadtran simulations {flight}"
        for infile, outfile, log_file in zip(tqdm(input_files, desc=tqdm_desc), output_files, error_logs):
            with open(infile, "r") as ifile, open(outfile, "w") as ofile, open(log_file, "w") as lfile:
                processes.add(Popen([uvspec_exe], stdin=ifile, stdout=ofile, stderr=lfile))
            if len(processes) >= max_processes:
                os.wait()
                processes.difference_update([p for p in processes if p.poll() is not None])

        # wait for all simulations to finish
        while len(processes) > 0:
            os.wait()
            # this will remove elements of the set which are also in the list.
            # the list has only terminated processes in it,
            # p.poll returns a non None value if the process is still running
            processes.difference_update([p for p in processes if p.poll() is not None])

        # %% check if all simulations created an output and rerun them if not
        file_check = sum([os.path.getsize(file) == 0 for file in output_files])
        # if file size is 0 -> file is empty
        counter = 0  # add a counter to terminate loop if necessary
        try:
            while file_check > 0:
                files_to_rerun = [f for f in input_files if os.path.getsize(f.replace(".inp", ".out")) == 0]
                # rerun simulations
                for infile in tqdm(files_to_rerun, desc="redo libRadtran simulations"):
                    with open(infile, "r") as ifile, \
                            open(infile.replace(".inp", ".out"), "w") as ofile, \
                            open(infile.replace(".inp", ".log"), "w") as lfile:
                        processes.add(Popen([uvspec_exe], stdin=ifile, stdout=ofile, stderr=lfile))
                    if len(processes) >= max_processes:
                        os.wait()
                        processes.difference_update([p for p in processes if p.poll() is not None])

                # wait for all simulations to finish
                while len(processes) > 0:
                    # this will remove elements of the set which are also in the list.
                    # the list has only terminated processes in it,
                    # p.poll returns a non None value if the process is still running
                    processes.difference_update([p for p in processes if p.poll() is not None])
                # update file_check
                file_check = sum([os.path.getsize(file) == 0 for file in output_files])
                counter += 1
                if counter > 10:
                    raise UserWarning(f"Simulation of {files_to_rerun} does not compute!\nCheck for other errors!")
        except UserWarning as e:
            log.info(f"{e}\nMoving to next flight")
            continue

        # %% merge output files and write a netCDF file
        latitudes, longitudes, time_stamps, saa = list(), list(), list(), list()

        log.info("Reading input files and extracting information from it...")
        for infile in tqdm(input_files, desc="Input files"):
            lat, lon, ts, header, wavelengths, integrate_flag = get_info_from_libradtran_input(infile)
            latitudes.append(lat)
            longitudes.append(lon)
            time_stamps.append(ts)
            # convert timestamp to datetime object with timezone information
            dt_ts = ts.to_pydatetime().astimezone(dt.timezone.utc)
            saa.append(get_azimuth(lat, lon, dt_ts))  # calculate solar azimuth angle

        log.info("Merging all output files and adding information from input files...")
        output = pd.concat([pd.read_csv(file, header=None, names=header, sep="\s+")
                            for file in tqdm(output_files, desc="Output files")])
        if "lambda" in header:
            # here a spectral simulation has been performed resulting in more than one line per file
            nr_wavelenghts = len(output["lambda"].unique())  # retrieve the number of wavelengths which were simulated
            time_stamps = np.repeat(time_stamps, nr_wavelenghts)
            # retrieve wavelength independent variables from files
            # since the data frames are all concatenated with their original index we can use only the rows with index 0
            zout = output.loc[0, "zout"]
            sza = output.loc[0, "sza"]

        output = output.assign(time=time_stamps)
        output = output.set_index(["time"]) if integrate_flag else output.set_index(["time", "lambda"])
        # calculate direct fraction
        output["direct_fraction"] = output["edir"] / (output["edir"] + output["edn"])
        if solar_flag:
            # convert mW/m2 to W/m2 (see page 43 of manual)
            output["edir"] = output["edir"] / 1000
            output["eup"] = output["eup"] / 1000
            output["edn"] = output["edn"] / 1000
            # calculate solar clear sky downward irradiance
            output["fdw"] = output["edir"] + output["edn"]

        # convert output altitude to m
        output["zout"] = output["zout"] * 1000
        # set up some metadata
        integrate_str = "integrated " if integrate_flag else ""
        wavelenght_str = f"wavelength range {wavelengths[0]} - {wavelengths[1]} nm"

        # set up metadata dictionaries for solar (shortwave) flux
        var_attrs_solar = dict(
            albedo=dict(units="1", long_name="surface albedo", standard_name="surface_albedo"),
            altitude=dict(units="m", long_name="height above mean sea level", standard_name="altitude"),
            direct_fraction=dict(units="1", long_name="direct fraction of downward irradiance", comment=wavelenght_str),
            edir=dict(units="W m-2", long_name=f"{integrate_str}direct beam irradiance",
                      standard_name="direct_downwelling_shortwave_flux_in_air",
                      comment=wavelenght_str),
            edn=dict(units="W m-2", long_name=f"{integrate_str}diffuse downward irradiance",
                     standard_name="diffuse_downwelling_shortwave_flux_in_air_assuming_clear_sky",
                     comment=wavelenght_str),
            eup=dict(units="W m-2", long_name=f"{integrate_str}diffuse upward irradiance",
                     standard_name="surface_upwelling_shortwave_flux_in_air_assuming_clear_sky",
                     comment=wavelenght_str),
            fdw=dict(units="W m-2", longname=f"{integrate_str}total solar downward irradiance",
                     standard_name="solar_irradiance", comment=wavelenght_str),
            latitude=dict(units="degrees_north", long_name="latitude", standard_name="latitude"),
            longitude=dict(units="degrees_east", long_name="longitude", standard_name="longitude"),
            saa=dict(units="degree", long_name="solar azimuth angle", standard_name="solar_azimuth_angle",
                     comment="clockwise from north"),
            sza=dict(units="degree", long_name="solar zenith angle", standard_name="solar_zenith_angle",
                     comment="0 deg = zenith"),
            CLWD=dict(units="g m^-3", long_name="cloud liquid water density",
                      standard_name="mass_concentration_of_cloud_liquid_water_in_air"),
            CIWD=dict(units="g m^-3", long_name="cloud ice water density",
                      standard_name="mass_concentration_of_cloud_ice_water_in_air"),
            p=dict(units="hPa", long_name="atmospheric pressure", standard_name="air_pressure"),
            T=dict(units="K", long_name="air temperature", standard_name="air_temperature")
        )

        # set up metadata dictionaries for terrestrial (longwave) flux
        var_attrs_terrestrial = dict(
            albedo=dict(units="1", long_name="surface albedo", standard_name="surface_albedo"),
            altitude=dict(units="m", long_name="height above mean sea level", standard_name="altitude"),
            direct_fraction=dict(units="1", long_name="direct fraction of downward irradiance", comment=wavelenght_str),
            edir=dict(units="W m-2", long_name=f"{integrate_str}direct beam irradiance",
                      standard_name="direct_downwelling_longwave_flux_in_air",
                      comment=wavelenght_str),
            edn=dict(units="W m-2", long_name=f"{integrate_str}downward irradiance",
                     standard_name="downwelling_longwave_flux_in_air_assuming_clear_sky",
                     comment=wavelenght_str),
            eup=dict(units="W m-2", long_name=f"{integrate_str}upward irradiance",
                     standard_name="surface_upwelling_longwave_flux_in_air_assuming_clear_sky",
                     comment=wavelenght_str),
            latitude=dict(units="degrees_north", long_name="latitude", standard_name="latitude"),
            longitude=dict(units="degrees_east", long_name="longitude", standard_name="longitude"),
            saa=dict(units="degree", long_name="solar azimuth angle", standard_name="soalr_azimuth_angle",
                     comment="clockwise from north"),
            sza=dict(units="degree", long_name="solar zenith angle", standard_name="solar_zenith_angle",
                     comment="0 deg = zenith"),
            CLWD=dict(units="g m^-3", long_name="cloud liquid water density",
                      standard_name="mass_concentration_of_cloud_liquid_water_in_air"),
            CIWD=dict(units="g m^-3", long_name="cloud ice water density",
                      standard_name="mass_concentration_of_cloud_ice_water_in_air"),
            p=dict(units="hPa", long_name="atmospheric pressure", standard_name="air_pressure"),
            T=dict(units="K", long_name="air temperature", standard_name="air_temperature")
        )

        # set up global attributes
        # CIRRUS-HL
        attributes = dict(
            title=f"Simulated downward and upward irradiance along flight track for experiment {experiment}",
            Conventions="CF-1.9",
            camapign_id=f"{campaign.swapcase()}",
            platform_id="HALO",
            version_id="1",
            comment=f"CIRRUS-HL Campaign, Oberpfaffenhofen, Germany, {flight}",
            contact="PI: m.wendisch@uni-leipzig.de, Data: johannes.roettenbacher@uni-leipzig.de",
            history=f"Created {dt.datetime.utcnow():%c} UTC",
            institution="Leipzig Institute for Meteorology, Leipzig University, Stephanstr.3, 04103 Leipzig, Germany",
            source="libRadtran 2.0.4",
            references="Emde et al. 2016, 10.5194/gmd-9-1647-2016"
        )
        # HALO-AC3
        global_attrs = dict(
            title=f"Simulated downward and upward irradiance along flight track for experiment {experiment}",
            Conventions="CF-1.9",
            campaign_id=f"{campaign.swapcase()}",
            platform_id="HALO",
            version_id="1",
            institution="Leipzig Institute for Meteorology, Leipzig, Germany, Stephanstr.3, 04103 Leipzig, Germany",
            history=f"created {dt.datetime.utcnow():%c} UTC",
            contact="Johannes RÃ¶ttenbacher, johannes.roettenbacher@uni-leipzig.de",
            PI="AndrÃ© Ehrlich, a.ehrlich@uni-leipzig.de",
            source="libRadtran 2.0.4",
            references="Emde et al. 2016, 10.5194/gmd-9-1647-2016",
        )

        encoding = dict(time=dict(units="seconds since 2017-01-01"))

        ds = output.to_xarray()
        # overwrite zout and sza in the spectral case
        ds = ds.assign(zout=xr.DataArray(zout, coords={"time": ds.time})) if not integrate_flag else ds
        ds = ds.assign(sza=xr.DataArray(sza, coords={"time": ds.time})) if not integrate_flag else ds

        # add the time dependent variables from the input files
        ds = ds.assign(saa=xr.DataArray(saa, coords={"time": ds.time}))
        ds = ds.assign(latitude=xr.DataArray(latitudes, coords={"time": ds.time}))
        ds = ds.assign(longitude=xr.DataArray(longitudes, coords={"time": ds.time}))

        ds.attrs = global_attrs if campaign == "halo-ac3" else attributes  # assign global attributes
        ds = ds.rename({"zout": "altitude"})
        if "lambda" in header:
            ds = ds.rename({"lambda": "wavelength"})
        # set attributes of each variable
        var_attrs = var_attrs_solar if solar_flag else var_attrs_terrestrial
        for var in ds:
            ds[var].attrs = var_attrs[var]
            encoding[var] = dict(_FillValue=None)  # remove the default _FillValue attribute from each variable
        # save file
        ds.to_netcdf(nc_filepath, encoding=encoding)
        log.info(f"Saved {nc_filepath}")
