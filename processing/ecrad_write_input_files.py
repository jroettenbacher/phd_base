#!/usr/bin/env python
"""Use a processed IFS output file and generate one ecrad input file for each time step

**Required User Input:**

* step: at which intervals should the IFS data be interpolated on the aircraft data

**Output:**

* well documented ecRad input file in netCDF format for each time step

*author*: Johannes RÃ¶ttenbacher
"""
# %% module import
import pylim.helpers as h
import pylim.solar_position as sp
from pylim.ecrad import apply_ice_effective_radius, apply_liquid_effective_radius
import numpy as np
import xarray as xr
import os
import pandas as pd
from datetime import datetime
from tqdm import tqdm
import logging
import time
from distutils.util import strtobool

start = time.time()
log = logging.getLogger(__name__)
log.addHandler(logging.StreamHandler())
log.setLevel(logging.INFO)

# %% read in command line arguments
args = h.read_command_line_args()
# set interpolate flag
t_interp = strtobool(args["t_interp"]) if "t_interp" in args else False  # interpolate between timesteps?
date = args["date"] if "date" in args else "20210629"
init_time = args["init"] if "init" in args else "00"
flight = args["flight"] if "flight" in args else "Flight_20210629a"
aircraft = args["aircraft"] if "aircraft" in args else "halo"
campaign = args["campaign"] if "campaign" in args else "cirrus-hl"
dt_day = datetime.strptime(date, '%Y%m%d')  # convert date to date time for further use
# print options to user
log.info(f"Options set: \ncampaign: {campaign}\naircraft: {aircraft}\nflight: {flight}\ndate: {date}"
         f"\ninit time: {init_time}Z\nt_interp: {t_interp}")

# %% set paths
path_ifs_output = os.path.join(h.get_path(campaign, "ifs"), date)
path_ecrad = os.path.join(h.get_path(campaign, "ecrad"), date, "ecrad_input")
# create output path
h.make_dir(path_ecrad)

# %% read in intermediate files from read_ifs
if init_time == "yesterday":
    ifs_date = int(date) - 1
    init_time = 12
else:
    ifs_date = date

nav_data_ip = pd.read_csv(f"{path_ifs_output}/nav_data_ip_{date}.csv", index_col="time", parse_dates=True)
data_ml = xr.open_dataset(f"{path_ifs_output}/ifs_{ifs_date}_{init_time}_ml_processed.nc")

# %% subsample 2s nav_data by step
step = 1
nav_data_ip = nav_data_ip[::step]

# %% loop through time steps and write one file per time step
idx = len(nav_data_ip)
dt_nav_data = nav_data_ip.index.to_pydatetime()

for i in tqdm(range(0, idx), desc="Time loop"):
    # select a 3 x 11 lat/lon grid around closest grid point
    lat_id = h.arg_nearest(data_ml.lat, nav_data_ip.lat.iat[i])
    lon_id = h.arg_nearest(data_ml.lon, nav_data_ip.lon.iat[i])
    lat_circle = np.arange(lat_id-1, lat_id+2)
    lon_circle = np.arange(lon_id-5, lon_id+6)
    ds_sel = data_ml.isel(lat=lat_circle, lon=lon_circle)

    if t_interp:
        dsi_ml_out = ds_sel.interp(time=dt_nav_data[i])  # interpolate to time step
    else:
        dsi_ml_out = ds_sel.sel(time=dt_nav_data[i], method="nearest")  # select closest time step

    # add cos_sza for each grid point using only model data
    cos_sza = np.empty((len(lat_circle), len(lon_circle)))
    sza = np.empty((len(lat_circle), len(lon_circle)))
    sod = nav_data_ip.seconds.iloc[i]
    for lat_idx in range(cos_sza.shape[0]):
        for lon_idx in range(cos_sza.shape[1]):
            p_surf_nearest = dsi_ml_out.pressure_hl.isel(lat=lat_idx, lon=lon_idx,
                                                         half_level=137).values / 100  # hPa
            t_surf_nearest = dsi_ml_out.temperature_hl.isel(lat=lat_idx, lon=lon_idx,
                                                            half_level=137).values - 273.15  # degree Celsius
            ypos = dsi_ml_out.lat.isel(lat=lat_idx).values
            xpos = dsi_ml_out.lon.isel(lon=lon_idx).values
            sza[lat_idx, lon_idx] = sp.get_sza(sod / 3600, ypos, xpos, dt_day.year, dt_day.month, dt_day.day,
                                               p_surf_nearest, t_surf_nearest)
            cos_sza[lat_idx, lon_idx] = np.cos(sza[lat_idx, lon_idx] / 180. * np.pi)

    dsi_ml_out["cos_solar_zenith_angle"] = xr.DataArray(cos_sza,
                                                        dims=["lat", "lon"],
                                                        attrs=dict(unit="1",
                                                                   long_name="Cosine of the solar zenith angle"))

    # calculate effective radius for all levels
    dsi_ml_out = apply_ice_effective_radius(dsi_ml_out)
    dsi_ml_out = apply_liquid_effective_radius(dsi_ml_out)
    # drop dimension column by selecting it, then stack lat, lon to a multi index named column, reset the index,
    # turn lat, lon, time into variables for cleaner output and to avoid later problems when merging data
    # this turns the two dimensions lat lon into one new dimension column with which ecrad can work
    dsi_ml_out = dsi_ml_out.sel(column=0).stack(column=("lat", "lon")).reset_index("column").reset_coords(
        ["lat", "lon", "time"])
    # some variables now need to have the dimension column as well
    variables = ["overlap_param", "fractional_std", "inv_cloud_effective_size"]
    n_column = dsi_ml_out.dims["column"]
    for var in variables:
        arr = dsi_ml_out[var].values
        # add new dimension to 1D variable and repeat the array times len(column)
        # then concatenate all array along the new dimension
        # check the shape of the input array and adjust the axis argument accordingly
        axis = 0 if arr.ndim == 0 else 1
        # define the dims accordingly
        dims = ["column"] if axis == 0 else [dsi_ml_out[var].dims[0], "column"]
        arr2D = np.concatenate([arr[..., np.newaxis]] * n_column, axis=axis)
        dsi_ml_out[var] = xr.DataArray(arr2D, dims=dims, attrs=dsi_ml_out[var].attrs)
    dsi_ml_out = dsi_ml_out.transpose("column", ...)
    dsi_ml_out = dsi_ml_out.astype(np.float32)  # change type from double to float32

    # ds_ml_out.to_netcdf(path=f"{path_ecrad}/ecrad_input_standard_{nav_data_ip.time.iloc[i]:7.1f}_sod_inp.nc4",
    #                     format='NETCDF4')
    dsi_ml_out.to_netcdf(path=f"{path_ecrad}/ecrad_input_standard_{nav_data_ip.seconds.iloc[i]:7.1f}_sod_inp.nc",
                         format='NETCDF4_CLASSIC')
    # dsi_ml_out.to_netcdf(path=f"{path_ecrad}/{date}/ecrad_input_standard_{nav_data_ip.time.iloc[i]:7.1f}_sod_inp.nc",
    #                      format='NETCDF3_CLASSIC')

log.info(f"Done with date {date}: {h.seconds_to_fstring(time.time() - start)} [hr:min:sec]")
